{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fecba5d8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Smart Facility: Inventory Dataset Basic - Demo Notebook\n",
    "\n",
    "Demo 1: Filtering/querying the dataset based on metadata.  \n",
    "Demo 2: Visualizing labels for a specific video.\n",
    "\n",
    "Note: this notebook relies on the `infinity-tools` python module, which can be installed following instructions [here](https://github.com/toinfinityai/infinity-tools#installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28322940",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from pycocotools.coco import COCO\n",
    "from IPython.display import clear_output\n",
    "from infinity_tools.spills import vis\n",
    "from infinity_tools.common.vis.videos import parse_video_frames, stack_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2772853",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Demo 1: Dataset Filtering\n",
    "\n",
    "We first show how to load the dataset's metadata into an easily filtered dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ef92f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATASET_FOLDER = \"sample_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a52a41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_param_paths = sorted(glob.glob(os.path.join(PATH_TO_DATASET_FOLDER, \"*_params.json\")))\n",
    "\n",
    "metadata = []\n",
    "for param_path in all_param_paths:\n",
    "    metadata_dict = {}\n",
    "    metadata_dict[\"video_number\"] = os.path.basename(param_path).split(\"_\")[0]\n",
    "    parameters = json.load(open(param_path))[\"params\"]\n",
    "    metadata_dict.update(parameters)\n",
    "    metadata.append(metadata_dict)\n",
    "\n",
    "metadata = pd.DataFrame(metadata)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51027f0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can now filter and/or query the dataset for specific properties, as shown in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44774292",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered_samples = metadata.query(\"camera_z >= 2.5\").query('shelf_fill_factor <= 0.9')\n",
    "display(filtered_samples.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57719a56",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Demo 2: Label Visualization\n",
    "\n",
    "We next show how to visualize labels for a specific inventory video. We do this using the dataset sample provided in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d09b196",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_all_labels(video_rgb_path: str) -> str:\n",
    "    \"\"\"Visualizes RGB, bounding boxes and segmentation masks in single video.\"\"\"\n",
    "\n",
    "    output_directory = os.path.dirname(video_rgb_path)\n",
    "    labels_path = video_rgb_path.replace(\".mp4\", \"_labels.json\")\n",
    "    seg_zip_path = video_rgb_path.replace(\".mp4\", \"_segmentation.zip\")\n",
    "    \n",
    "    seg_extracted_path = seg_zip_path.replace(\".zip\", \"\")\n",
    "    os.makedirs(seg_extracted_path, exist_ok=True)\n",
    "\n",
    "    with zipfile.ZipFile(seg_zip_path, \"r\") as zf:\n",
    "        zf.extractall(seg_extracted_path)\n",
    "\n",
    "    imgs = parse_video_frames(video_rgb_path)\n",
    "    image_dims = (imgs.shape[2], imgs.shape[1])\n",
    "    fps = 3\n",
    "    coco = COCO(labels_path)\n",
    "\n",
    "    bounding_box_path = vis.create_bounding_boxes_video(\n",
    "        os.path.join(output_directory, \"bounding_box.mp4\"), imgs, fps, coco, image_dims\n",
    "    )\n",
    "    segmentation_path = vis.create_segmentation_video(\n",
    "        os.path.join(output_directory, \"segmentation.mp4\"),\n",
    "        seg_extracted_path,\n",
    "        fps,\n",
    "        image_dims,\n",
    "    )\n",
    "\n",
    "    merged_video_path = stack_videos(\n",
    "        paths=[video_rgb_path, bounding_box_path, segmentation_path], \n",
    "        axis=2,\n",
    "        output_path=os.path.join(output_directory, \"labels.mp4\")\n",
    "    )\n",
    "    \n",
    "    remove_paths = [bounding_box_path, segmentation_path]\n",
    "    for e in remove_paths:\n",
    "        os.remove(e)\n",
    "    shutil.rmtree(seg_extracted_path)\n",
    "    clear_output()\n",
    "\n",
    "    return merged_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f7576",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "video_rgb_path = \"./sample_data/00000.mp4\"\n",
    "labels_video_path = visualize_all_labels(video_rgb_path)\n",
    "print(f\"The resulting labels video can be viewed at: {labels_video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}